# PhotoTouch: A Multimodal User Interface for Photo Editing
PhotoTouch is a multimodal user interface for photo editing. It has standard and intelligent image processing tools, [1]. In  addition to that it uses Image Recognition, Speech Recognition APIs to enhace the interface features. A simple competitor for PixelTone of Adobe. https://youtu.be/1S2e8RWB0xE

Prepared as a term project for the Intelligent User Interfaces course at Koç University.

# Project Description:
Recent technology, on majority, is a result of the rapid expansion of the field of Machine Learning(ML). We assemble recent ML techniques from the perspective of image processing. In order to achieve this task, we get inspired by a recently released iOS program, so called PixelTone. PixelTone has a different aim at solving photo editing difficulties in small mobile devices. Here, our aim is to expose a modern approach to basic photo editing tools. In our PhotoTouch, we have combined ML techniques such as pixelwise segmentation, speech recognition and sentiment analysis. 
The design of a photo consists of three major steps. (1) Preparation: This step let designer to analyze image and decide what to reflect in later stages. This step is ideal and technique preparation to final result. Histogram is a tool, in this stage. (2) Processing: This step consists of segmentation, adding background and drawing. (3) Postprocessing: Sepia, gray, posterize are some examples of the image processing belongs to this stage. The problem is that these stages are not well defined on basic editors. We would like to let user to apply these stages by using some automated routines. These routines, for instance, decide to use gray, sepia or posterize according to your sentiment, decide by the magnitude of sentiment to tonality of sepia, or poster quantization levels. As solving the problem of unstructured, unordered editing, we automate these processes at the same time. Additionally, we have designed this tool especially for Microsoft Surface Studio computers considering their touch and flexible hardware interface.
## How it works?
Our program let user to select an image from his/her folder. After this stage, you observe the histogram and at the same time Mask-RCNN (Pixelwise segmentation algorithm) analyze image and show off gray transparent bounding boxes on each object recognized. By right clicking the bounding box, you can select from the options: adding background or selecting all objects recognized. After this option, just clicking on bounding box performs the segmentation. However, if you select the background option, computer asks your opinion on the objects and decide on its own which background to use from its collection. This is the sentiment analysis. After this step, you can click on AutoProcess that uses the previous speech as for sentiment analysis and according to your opinion decide which color operation to apply, sepia, gray or posterize. At the end, by clicking on AutoAdd button and calling the computer, for example, “add a puppy”. It inserts a cute puppy on the image.
## Technical Aspects:
### The basics:
The program has the basic properties like open a file, save a file, cut, copy and crop of some part of the image. All are done by using tkinter tool box. Open function calls the filedialog, and by filedialog user determines the location of image file and by using Pillow library open the image and then the image is copied to the canvas. Canvas is the window that interface with user visually. Save operation is also similar, but the reverse, copy from the canvas and save on file. Lastly, crop function uses several functions at once. In order to crop, first you need to draw a window by pressing the left button on mouse. This is achieved by bind function. When you leave the button there you observe a window that is a transparent gray. That is the region. The properties we call in bind function are subsequently “<ButtonPress-1>”, “<B1-Motion>” and “<ButtonRelease-1>” where each calls a different function that performs. These functions basically locate the start and end points on canvas and the other draw the transparent layer on image that indicates the region. At the end, you press enter, it crops between given corner points. 
### Intensity Histogram:
In image processing, histogram is a powerful image analysis tool. An image represented with 256 different integer intensities, [0,255]. For color images, there are three colors; red, green, blue. In image matrix, these three colors are represented distinctly. An intensity histogram counts the number of observations each belongs to a certain intensity and for color images there are different lines representing each color. In our representation, we use the histogram function to get the statistics and draw a small circle on canvas. In the right image, the vertical line represents the count, observation statistics, while the horizontal line represent the intensities ranging from 0 to 256. Each color represented with its color. You can observe that the histogram is a continuous function. This is the case in natural images. The transitions from intensities to intensities are smooth. However, a synthetic image might quantize at certain values and may not be continuous.  
### Segmentation:
While you are loading the image, at the same time Neural Network(NN) based pixelwise segmentation algorithm works. The NN trained on MS-COCO dataset which consists of 80 objects. Whenever the algorithm recognizes those objects, the corresponding pixels are labeled. Thus, one has labeling of each object in pixels and can use these pixels as mask to segment out from the image. As you know the pixels that each object consists of, you can use bounding box to show off the object. We have used gray transparent bounding boxes. At right image you see three zebras and one giraffe. Each are labeled in pixel wise and displayed in a bounding box. When you right click the bounding box, a pop-up menu with three options appears. There you can choose “cropAll?”, as choosing this option all recognized objects can be cropped. Otherwise, only the object that you left click will be cropped.
### Speech recognition & Sentiment analyses (SRSA):
We have mentioned that our UI consists of three stages: preparation, processing and postprocessing. We have use SRSA in second and third stages as a key element. The use of sentiment in the second stage is after the pixelwise segmentation is carried out, if you have selected the adding a background, computer asks about your opinion on image. Here the speech recognition comes into play and transcribe the audio recorded of user. The second phase is to decide whether the comment is positive or negative. This is sentiment analyses. For a given text, sentiment analysis toolbox gives a score positive, neutral or negative. From the collection program choose an appropriate background for you. The use of sentiment in the third stage is If the sentiment is positive, then we apply posterize since this effect evoke positive feelings. If the sentiment score is neutral, then the image converted to gray and lastly if the score is negative, we apply sepia tonality. Second point to know is the magnitude of sentiment. A score can be either positive or negative, it has a magnitude reflects its degree of positiveness or negativeness. This magnitude of sentiment Is used to determine, for instance, the tonality of sepia, or number quantization levels of posterize. In sum, we have recognized the speech input by the user, then we apply sentiment analysis. This analysis has two components, score and magnitude, both are used a definer for color effects.
### Background:
If you select the option “addBackground?” shown in Figure 2, PhotoTouch please you to comment on the objects. By this way, program chooses an appropriate background for cropped images. This is done by SRSA (Speech recognition & Sentiment Analyses). According to the sentiment score that you have there are three options shown at right. The most left one is positive, middle is neutral and the most right one is negative.
### Color manipulation:
There are three color manipulation we have implemented. (1) Sepia: It is reddish-brown color. What we have implemented here is Red and Green intensive sepia. First, we calculate for each pixel the average pixel intensity over three colors and adding +75 on average to red and +25 to green.  If the magnitude of sentiment is above a threshold +150 to red and +50 to green. (2) Gray: This is pixelwise averaging the intensities over three channels. Since It corresponds to neutral sentiment, it has no tonality. (3) Posterize: This process is level quantization. You quantize each channel intensities into 5 levels or if the sentiment magnitude is higher than a threshold quantizes to 3 levels. All these three operations are pixelwise operations.  We have decided on those manipulations to reflect emotions into the canvas. Since sepia as a brownish color reminds us the fall, and gray is always neutral color, and lastly the posterize effect is very lifeful.
### Drawing:
Our program also has another basic functionality of drawing. The Python3 library Pillow has a function ImageDraw. ImageDraw lets users to edit on image as drawing with a certain brush. We use a elliptic shape brush. It is predefined on the algorithm. It is 10 by 10 pixel-wide. There are also 12 colors that you can draw, and it appears as pop-up window. In the palette, they appear as background color. Whenever you choose a color, window disappears.
### Insert cute animals:
Lastly, we have added a strict voice command for the last step that inserts a cute animal, for instance a puppy onto the image. This can be thought as sticker, or a logo. In order to do that first we need speech recognition. With speech recognition the live audio to text conversion is carried out. Then, if the keywork does match with our sticker library, we have created a mask out of the puppy picture we want to add. Then, sum the inverse mask times image with the puppy image. In Figure 4, the bird and puppy are some examples of this AutoAdd function.
## Novelties:
There are two other user interface, we would like to compare. One is PixelTone; it is AI powered photo editing tool. The other one is Paint; standard editing tool comes with OS. PhotoTouch can be taught as combination of those two. PixelTone also has segmentation property. For example, this program can alter the color of a t-shirt on image. We use segmentation in cropping out objects from the pictures. Again, PixelTone has Speech Recognition property as we have. But PixelTone is mostly color editing platform. On contrary, we use Speech Recognition together with Sentiment Analyses in order to decide properties like background, color manipulation and stickers. Although, PixelTone does not have drawing tool, we and Paint both use drawing for further manipulations on image.
```markdown
| Properties          | PhotoTouch | PixelTone | Paint |
| Segmentation        | Yes        | Yes       | No    |
| Speech Recognition  | Yes        | Yes       | No    |
| Sentiment Analyses  | Yes        | No        | No    |
| Background          | Yes        | No        | Yes   |
| Color manipulation  | Yes        | Yes       | No    |
| Drawing             | Yes        | No        | Yes   |
| Insert stickers     | Yes        | No        | No    |
```
Another point that our program distinguish itself from the others is the perspective of structured editing pipeline. You might have found yourself in a position that you do not know what to do, how to edit in front of a photo editing program. For example, you may open Paint and might not know what manipulations you need or open PixelTone and might not decide which color to pick or which color level you need to adjust. In PhotoTouch, we have designed the program such that you open image and decide the segment out with a background and later on color manipulations. All done by your sentiment analyses. 
## Technologies Used:
### Python3 and its packages:
We have implemented our code in Python3 environment. It is easy to use programming language. It is also easy to install. In Linux environment, you can just install from repository. Tkinter: Tkinter module or TK is the standard Python GUI interface. It works both on Windows and Linux. It is easy to install with “pip3 install” command. Skimage: scikit-image is a collection of image processing algorithms, we mostly use for open images. It is easy to install with “pip3 install” command.  Pillow: It is the Python imaging library. It is easy to install with “pip3 install” command. ImageDraw library that let us to use drawing on image is also from this library.
### Google Cloud Speech Recognition:
Google Cloud Speech-to-Text is a API that let users to convert audio to text by applying neural network models. This API has two features for long and short audios. We use short, so called Synchronous speech recognition. The voice that is recorded send to cloud and processed back as a text file. This process depends on internet connection. It does not work offline. You can also reduce noise. The algorithm that is applied on this audio files by Google is in sum CTC+RNN neural networks. CTC (Connectionist Temporalist Classification) is a way of calculating loss function for unlabeled sequences and RNN let user to work with sequences. Main difficulty of this API is that it is very hard to pronounce English sentences well, API always comes with a different version from what you have said. Easy to install and apply library with pip3 install command.
### Google Cloud NLP:
This API applies sentiment analysis on transcribed texts. The overall attitude (positive or negative) are attempted to be captured by two numerical values, score and magnitude. Score is a number between -1 and 1 and magnitude can be from 0 to Inf. This recurrent neural network is trained on IMDB movie reviews dataset. This dataset consists of positive and negative comments on movies with their ratings. In order to use this service, you need to apply for credentials from google cloud. Generally, sentiment analysis is carried out by multi-layer RNNs, these are deep RNNs, an LSTM for example. After the sequence finishes the features that you get is interpreted by a densely connected layer whether it is a positive or negative comment. The main difficulty of this application is that for short sentences the sentiment is not very clear. However, for longer sentences, API is slow. Easy to install and apply library with pip3 install command.
### Mask RCNN:
We need a segmentation tool for our project and decided on Mask RCNN as a good Neural Network alternative in order to construct fully autonomous segmentation. This algorithm, for a given image, calculates a mask that covers the object. The main difficulty of this algorithm is its inexact cropping behavior. There occurs that some parts of the object could not be identified within the object.
Mask RCNN is a branch of RCNN family object detection algorithms. These algorithms based on Convolutional Neural Networks and in extra Mask RCNN has region proposal network (RPN). This network by just looking at feature map of the last layer, produce region proposals. Mask RCNN adds an extra layer that inputs CNN feature map and outputs a mask with 1s and 0s indicating the location of object. As a result, it creates a binary, pixelwise mask. But for Mask RCNN is to work, we also need small adjustments. Inside the Mask RCNN instead of VGG, ResNet101 network used as a feature extractor. Deep Residual Networks allow networks to by-pass layers and uses less deeper solutions, possibly existing. Our network is trained on MS-COCO dataset.
### MS-COCO:
This dataset consists of 200K images with 80 object categories. In total, 1 and half millions of object instances exists. 

## Related Works:
Kaiming He, Georgia Gkioxari, Piotr Dollár: “Mask R-CNN”, 2017; [http://arxiv.org/abs/1703.06870 arXiv:1703.06870]

Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick: “Microsoft COCO: Common Objects in Context”, 2014; [http://arxiv.org/abs/1405.0312 arXiv:1405.0312].

Gierad P. Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang, Aseem Agarwala, Jason Linder, and Eytan Adar. 2013. PixelTone: a multimodal interface for image editing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 2185-2194.
